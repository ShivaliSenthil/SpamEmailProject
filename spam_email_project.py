# -*- coding: utf-8 -*-
"""Spam_Email_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ly5MhXdEBFEPVqTeAUcLJIXPnh5laXkK
"""

import numpy as np
import pandas as pd

#Importing LogisticRegression Model
from sklearn.linear_model import LogisticRegression #Binary operations

#Importing accuracy score fuction
from sklearn.metrics import accuracy_score

#Importing train test split function
from sklearn.model_selection import train_test_split

#To convert all the strings formats into numeric
from sklearn.feature_extraction.text import TfidfVectorizer

#Importing the dataset
raw_mail_data=pd.read_csv("mail_data.csv")
raw_mail_data

raw_mail_data.info()

raw_mail_data.isnull().sum()

#replacing all the null values with null string
mail_data=raw_mail_data.where((pd.notnull(raw_mail_data)),'')
mail_data.info()

#checking  null values
raw_mail_data.isnull().sum()

#Printing the 5 rows
mail_data.head()

#checking the rows and columns of the dataset
mail_data.shape

"""LABEL ENCODING"""

#label spam mail as 0 and ham mails as 1
# mail_data.loc[mail_data['Category']=='ham','Category']=1

mail_data

# mail_data.loc[mail_data['Category']=='spam','Category']=0

mail_data['Category'] = mail_data['Category'].replace({'ham': 1, 'spam': 0})

#find the total number of ham email and spam email
mail_data['Category'].value_counts()

#separating the data as texts and label
X=mail_data['Message'] #Input feature
Y=mail_data['Category'] #Label

print(X)

print(Y)

#splitting the data into training data and testing data
#Training data = X_train,Y_train
#Testing data=X_test,Y_test
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=2)
print(X.shape,X_train.shape,Y_test.shape)

#transforming the text data to feature vectors that can be used as input to logistic regression
feature_extraction=TfidfVectorizer(min_df=1,stop_words='english',lowercase=True)
#min_df=1 removes the words which occur less than 1 time(minimum document frequency)
#stop_words=english , removes all the stopwords

X_train_num=feature_extraction.fit_transform(X_train)
X_test_num=feature_extraction.transform(X_test)

type(Y_train)

#Convert Y_train amd Y_test values as integers
Y_train=Y_train.astype('int')
Y_test=Y_test.astype('int')

"""Training the model"""

model=LogisticRegression()

#training the logistic regression model with the ( training data )
model.fit(X_train_num,Y_train)

#evaluating the Trained Model
X_train_prediction=model.predict(X_train_num)
#Finding the accuracy score on training data
training_data_accuracy=accuracy_score(Y_train,X_train_prediction)
print('Accuracy on training data : ',training_data_accuracy)

# Evaluating the Testing Model
X_test_prediction=model.predict(X_test_num)
testing_data_accuracy=accuracy_score(Y_test,X_test_prediction)
#Finding the accuracy score on testing data
print('Accuracy on testing data : ',testing_data_accuracy)

#Building a predictive system
input_mail=['Free Free Free You have won a lottery']
input_mail_num=feature_extraction.transform(input_mail)

#Making Prediction
prediction=model.predict(input_mail_num)
if prediction[0]==1:
  print("Ham Email")
else:
  print("Spam Email")

import joblib

# Assuming your model is stored in a variable called `model`
joblib.dump(model, "model3.pkl")

from google.colab import files
files.download("model3.pkl")

import joblib

# Save model
joblib.dump(model, "model3.pkl")

# Save vectorizer
joblib.dump(feature_extraction, "vectorizer3.pkl")